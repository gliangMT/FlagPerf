# 参评AI芯片信息

* 厂商：MThreads
* 产品名称：S4000
* 产品型号：/
* TDP：/

# 所用服务器配置

* 服务器数量：1
* 单服务器内使用卡数：1
* 服务器型号：/
* 操作系统版本：Ubuntu 20.04.4 LTS
* 操作系统内核：Linux 5.4.0-42-generic
* CPU：/
* docker版本：24.0.7
* 内存：1TiB
* 服务器间AI芯片直连规格及带宽：此评测样例无需服务器间通信

# 评测结果

## 核心评测结果

| 评测项  | INT8算力测试值   | INT8算力标定值  | 测试标定比例 |
| ---- | ----------- | ---------- | ------ |
| 评测结果 | / | / | / |

## 能耗监控结果

| 监控项  | 系统平均功耗  | 系统最大功耗  | 系统功耗标准差 | 单机TDP | 单卡平均功耗  | 单卡最大功耗 | 单卡功耗标准差 | 单卡TDP |
| ---- | ------- | ------- | ------- | ----- | ------- | ------ | ------- | ----- |
| 监控结果 | / | / | /   | /     | / | / | /  | /  |

## 其他重要监控结果

| 监控项  | 系统平均CPU占用 | 系统平均内存占用 | 单卡平均温度  | 单卡平均显存占用 |
| ---- | --------- | -------- | ------- | -------- |
| 监控结果 | /    | /   | / | /  |

# 厂商测试工具原理说明

使用GEMM算子进行computation-bound的计算任务，从而测得实际INT8算力

注：
INT8常被用于量化模型，目的是减小模型的存储需求和加快推理速度，同时尽量保持模型的精度。
在使用NVIDIA cuBLAS库进行INT8计算时，为防止矩阵乘法计算过程中发生溢出，cuBLAS库只提供8*8=32，即两个INT8数相乘结果存储为INT32的接口。因此在使用GEMM算子进行INT8计算时，不只使用了INT8 Tensor Core，INT8 GEMM的理论计算峰值也不是标定的624TOPS，此case评测结果仅供参考。
